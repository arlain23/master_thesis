The purpose of this thesis was to develop a system with which it will be possible to perform semantic image segmentation with the use of Conditional Random Fields. Before this system was created there was an excessive theoretical research conducted on what are the necessary steps and algorithms that may be used for this task. The created system was developed mostly from scratch and included an implementation of the described algorithms. The dissertation was mostly based on a book \textit{"Structured Learning and Prediction in Computer Vision"} by Sebastian Nowozin and Christoph H. Lampert and an article \textit{"TextonBoost for Image Understanding: Multi-Class Object Recognition and Segmentation by Jointly Modeling Texture, Layout, and Context"} written by Jamie Shotton et al. 

In this dissertation two sets of experiments were described. The first one was aimed to perform semantic segmentation on images into three classes, one for objects in the shades of red, second one for bluish regions and the third one for greenish. In the second set of experiments, objects were to be detected also by their shape. There was one extra class introduced that represented reddish objects with a shape of letter H surrounded by greenish superpixels, which should be distinguished from other red regions in the same surroundings. 

There were three main procedures required to achieve the task described in this dissertation. First of all, images had to be modelled in a way that makes further processing possible. A chosen method for this step was a factorisation process, which represented an image in terms of an undirected graph composed of two types of nodes, input nodes which decode image features, and output nodes, which are used to model the labelling of the system. Factor graphs are a perfect representation of Conditional Random Fields as they allow to model various types of features and contextual relations between image pixels, or superpixels. Features chosen to perform the experiments described in this dissertation were  based solely on colour, though they included also contextual information about colours in the neighbourhood of the processed region. For the second type of experiments an automatic feature selection based on stepwise regression was implemented that allowed choosing an optimal set of features with which data from images was modelled. The next core part of the developed system was aimed to train parameters of the established model using supervised machine learning methods based on the training set of images with known labellings. For this part Stochastic Gradient Descent algorithm was chosen. The last step concerned finding the optimal labelling for a set of previously unused test data in the process of inference. This was achieved by Loopy Belief Propagation, which is a message-passing algorithm used on graphical models to find such a sequence of states that has the largest probability of occurrence conditioned on known inputs. For semantic image segmentation this sequence is represented by a labelling of each superpixel of a given test image.

The first set of experiments described in this dissertation was aimed to present how the implemented algorithms work on a very basic example of image segmentation based on superpixel colour only. For images with only three colours available: red, green and blue, segmentation was correct in 100\% cases for all labels. In the next experiment, in which shades of those colours were introduced, the results were much worse, however, they were largely improved by expressing the features in CIELAB colour space. In this experiment, it was clear that because of the contextual nature of Conditional Random Fields segmentation results are more precise, as only after incorporating the pairwise potential, which models relations between neighbouring superpixel, did the precision expressed in Intersection over Union reach 100\%. Hence, for the first set of experiments, semantic image segmentation with use of Conditional Random Fields was successful. 

Second part of the system was devoted to distinguishing objects in an image based not only by their colour but also by their shape. For this task, a different feature function had to be defined which included also contextual data of the given superpixel surroundings. In order to conduct the experiments proposed for this part of the system, initial images were subjected to the process of colour quantisation, which limited available colours to three basic ones only. In the first experiment segmentation precision was equal to 99.54\%, with most mislabelled superpixels being in the last class that should represent objects with a shape of a letter H. Chosen features turned out to be insufficient to determine the proper class of narrow, red regions at the image boundaries, which were too similar to vertical stripes in a letter H and therefore wrongly assigned to class 3 instead of 1. With few exceptions the algorithm had no problems with correct labelling of other regions. In the last experiment noise was introduced to the process of colour quantisation, and the aim of Conditional Random Fields was to provide an expected configuration of labels regardless of the noise. A resulting mean Intersection over Union for all labels was equal to 98.39\%, and again class of objects shaped as a letter H had the lowest precision. However, in this experiment it was proved that proper definition of the feature function used for unary potential has a large influence on the final result. What is more, even without using the pairwise potential most of the noised superpixels were correctly labelled. The only problematic regions were on the boundaries of different objects, however, they effect of the noise in such regions was diminished when the pairwise potential was incorporated to the system.   

In general, during this thesis different algorithms and methods were tested in each step of the system implementation. A few simplifications had to be introduced, especially during the training phase and estimation of features probability density, without which even a simple semantic segmentation task would require a lot of time and resources. However, the chosen algorithms even after simplifications managed fulfil tasks specified by experiments conducted in the thesis. Even with not complex features used, which were based only on superpixel colours, the possibilities of Conditional Random Fields were visible. By incorporating contextual data to the model, which were based only on colours as well, it was possible to distinguish red objects on green neighbourhood that were differing only by their shape, which shows how powerful Conditional Random Fields may be once based on more complex features.