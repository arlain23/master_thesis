For semantic image segmentation, far more complex methods are required than for ordinary segmentation. As in case of any segmentation, there is a need of feature extraction and selection that will allow the distinction between objects. However, apart from specifying object boundaries, those features have to carry enough information to differentiate between objects on a higher level, in order to assign to them a semantic meaning. A conventional approach to this task would require using handcrafted features, which means such data that can be obtained from information present in the image itself \cite{segmentation_methods_descriptors}. Previously mentioned properties like intensity or edges are examples of such features. However, in practice more sophisticated algorithms for feature extraction are used. Instead of describing an image as a whole, first some specific points of interest, which represent areas significantly different from others can be detected. Then, having such regions, feature vectors are constructed from them, which are then needed for classification tasks. Such vectors are created with the use of algorithms named feature descriptors \cite{segmentation_methods_descriptors_2}. Their aim is to take an image as an input and encode information from regions of interest into a series of numbers describing a specific region. They incorporate features like local spatial information, gradients, histograms, object orientation or texture, which can be applied to differentiate one region from the other. For natural images, it is an extremely difficult task as the same object may come in various forms, sizes, shapes, colours etc. 

Having extracted feature vectors, classification algorithms are aimed to conduct semantic image segmentation basing on them. Traditionally algorithms like Support Vector Machines, Random Decision Forests were involved in this task. Though there are relatively old algorithms, as both were proposed around the 1990s \cite{decision_forests} \cite{Cortes1995},  they are still applicable and used for both classification and regression tasks. Support Vector Machine is a supervised learning algorithm which performs classification based on defining decision boundaries between classes. Similarly, Random Decision Forests involve supervised machine learning to solve classification and regression tasks. They are based on composing a classifier ensemble from a set of decision trees, which are independent on each other in a decision making process. It is done in order to obtain more accurate and robust prediction than in the case of a single, complex classifier. Those traditional methods are still applicable for classification tasks, lately more advanced, deep learning methods have become dominant in algorithms used for semantic image segmentation. 

Though, initial approaches to deep learning in this field date back to 2000s \cite{deep_learning_Ciresan} a breakthrough of using Deep Neural Networks for image segmentation happened in 2014 \cite{cnn_shelhamer} when a method of using Fully Convolutional Networks was introduced, which allowed image inputs of arbitrary size as opposed to first implementations that required it to be fixed. Since then, most of the algorithms used for semantic image segmentation have been based on this method.  Later in the same year \cite{cnn_liang}, a method combining Fully Convolutional Networks with Conditional Random Fields was proposed, which improved the results by better boundary detection and capturing of details. Conditional Random Fields, which will be further explained in this dissertation can themselves act as an independent classifier that can be used to perform semantic image segmentation. 
