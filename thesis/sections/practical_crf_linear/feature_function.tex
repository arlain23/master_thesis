The part of the system that is described in this chapter was aimed to present a basic example of how Conditional Random Fields can be used to perform the task of semantic segmentation on images. Therefore, only simple features were chosen to represent images from the dataset. As it has already been explained in \textit{section \ref{sec:energy}: \nameref{sec:energy}} there are two main groups of features that represent individual nodes in a factor graph. Features from the first group are bound to input nodes and are used for computing the unary potential, while the others are for pairwise potential computation between output nodes. When it comes to the latter type, for the part of the system that is described in this chapter, a binary pairwise feature was introduced. It is in a form of a two-dimensional vector that can take only two values: $[1,0]$ if the labels of a given pair are the same, or $[0,1]$ if they are different as it has been already presented in formula \ref{eq:fi_pairwise}. 

When it comes to the unary potential, only colour features of a given superpixels were taken into consideration. Every input factor can be described by three continuous numbers, each representing one colour component from a chosen colour space. As it was already explained in the theoretical section, the unary potential is dependent not only on the chosen features but also on the label which is under consideration. As this part of the system performs classification into three distinct classes, there are three weight vectors that are used to calculate an energy of the system, one per each label. Then, the unary potential used in this part of the system may be computed according to the formula \ref{eq:e1_nonlinear}. 
\begin{equation}
    \label{eq:e1_nonlinear}
    E_1(y_i,x_i,w)= 
    \begin{cases}
        \left \langle w_{1,0}, \varphi({x_i}) \right \rangle , &  \text{if } y_i = 0\\ 
        \left \langle w_{1,1}, \varphi({x_i}) \right \rangle , & \text{if } y_i = 1\\
        \left \langle w_{1,2}, \varphi({x_i}) \right \rangle , & \text{if } y_i = 2\\  
    \end{cases}
\end{equation}
However, such representation is not very convenient from an implementation point of view, especially during the parameter training process in which every weight of the system needs to be updated iteratively. Therefore, instead of having three distinct weight vectors, a single, joined weight vector can be proposed. Then, it will contain nine elements, as there are three colour components and three available classes. However, a nine-dimensional weight vector requires the feature vector to contain nine elements as well. Though colour features are independent of the assigned label as they are specific to a given superpixel and unchangeable during the segmentation process, such a feature function can be introduced that returns a different feature vector depending on a label. Thus, this vector would contain three elements representing a superpixel colour, one per each colour component and six other elements with values equal to 0. Then, depending on the label that is under consideration, those three elements describing superpixel colour would occupy a different section of a feature resulting vector. For label 0, they will be placed on indices 0-2, for label 1 on 3-5, and for the last label on positions 6-8. Hence, the formulas for a weight vector and a feature vector that were used in this part of the system can be defined as in equation \ref{eq:vectors_nonlinear}. Colour components are denoted as R, G, and B, though different colour space than RGB can also be used. A value of a single element in a feature vector is dependent on the difference between a label of a current vector position, denoted by $y_0$, $y_1$, or $y_2$, and a label of the superpixel that is under consideration. This difference can take a value of 0 if labels are the same, or 1 if they are not.
\begin{equation}
    \label{eq:vectors_nonlinear}
    \begin{matrix} 
        w_1 = \begin{bmatrix}
            w_{R,0}\\ 
            w_{G,0}\\
            w_{B,0}\\
            w_{R,1}\\ 
            w_{G,1}\\
            w_{B,1}\\
            w_{R,2}\\ 
            w_{G,2}\\
            w_{B,2}\\
        \end{bmatrix}
        & & &
        \varphi_1(x_i,y_i) = \begin{bmatrix}
            \phi_{R} \cdot (1-\left | y_0 - y_i \right |)\\ 
            \phi_{G} \cdot (1-\left | y_0 - y_i \right |)\\
            \phi_{B} \cdot (1-\left | y_0 - y_i \right |)\\
            \phi_{R} \cdot (1-\left | y_1 - y_i \right |)\\ 
            \phi_{G} \cdot (1-\left | y_1 - y_i \right |)\\
            \phi_{B} \cdot (1-\left | y_1 - y_i \right |)\\
            \phi_{R} \cdot (1-\left | y_2 - y_i \right |)\\ 
            \phi_{G} \cdot (1-\left | y_2 - y_i \right |)\\
            \phi_{B} \cdot (1-\left | y_2 - y_i \right |)\\
        \end{bmatrix}
    \end{matrix} 
\end{equation}

Having specified how the feature functions for unary and pairwise potential are defined, it is possible to perform parameter learning and then inference process. As the weight vector for unary potential contains nine elements, and two elements for pairwise potential, in overall, it is necessary to adjust eleven weights. 