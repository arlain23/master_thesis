A basis of both inference and parameter training is a proper formulation of an energy function, which reflects a probability of occurrence of a given configuration of variables in a system. In semantic image segmentation, without correctly defined energy function it will not be possible to differentiate objects of different classes. As it has already been presented, energy is composed of two terms: unary potential and pairwise potential. 
\begin{equation}
    E(Y=y,X=x) = \sum_{i \in V}{E_1(y_i,x_i)} +  \sum_{i,j \in V}{E_2(y_i,y_j)})
\end{equation}
In semantic image segmentation, unary component of the energy function predicts a label of a given pixel or region, based on some observed features of this part of an image. A feature can be described as a numeric representation of row data that is fetched from an image. The process of extracting and selecting those representations is a challenging task as without properly chosen features that provide all the required information to the model, it would not be possible to perform the assigned task. What is more it usually accounts for the vast majority of time that is needed to perform a machine learning task \cite{features_oreilly}. Proper formulation of a feature vector is a crucial step in machine learning as it reflects not only the level of the model complexity but also its performance. However, the relevance of available features is strictly bound to data and to the chosen model and due to to the large diversity in both data and models it is extremely difficult to generalise the process of feature engineering. Depending on the task some models can perform well given a large number of features while others require less, but more informative features. Though there exist some automatic or semiautomatic tools for feature engineering \cite{python_h2o, python_tpot, python_auto-sklearn}, that aim to make feature extraction less problem specific, still the vast majority of machine learning tasks use the traditional approach of manual feature selection \cite{feature_engineering}. 
Features used for any task within the area of image processing can be either low- or high-level \cite{feature_extraction_book}. Low-level features are such features that can be automatically extracted from an image such as pixel intensity, gradients, colours, edges or textures. They do not give any information about spatial relations between regions of an image. On the other hand, high-level features correlate data obtained from low-level features with a content of an image to provide information about shapes and objects, thus having a semantic meaning. 
Feature engineering is a time-consuming and demanding task of its own and it is not a part of this dissertation. Therefore, to stay within the scope of the thesis, feature extraction is limited only to features that are based solely on colour-related data. Hence, in the most basic form the unary potential of the energy function can be expressed as a linear relation between a weight vector $w$ and a feature vector $\varphi$ that is composed of colour values of each individual pixel.
A colour value can be expressed in a numerical form with use of a chosen colour space. A colour space is a mathematical model representing a colour value as tuple of typically three or four numbers. The most popular colour space being based on the physiology of a human eye is RGB model, in which an arbitrary colour value is expressed as combination of values of three primary colours, which are red, green, and blue. A different colour space, named CIELAB, was created in other to mimic a human perception of colours. The model is constructed on three axes, first being axis L* representing Lightness with values between 0 and 100. Axes a* and b* encode green-red and blue-yellow components respectively. There are many other colour spaces such as CMYK, HSV, HSL or YUV, each of them being more suitable for certain tasks \cite{colour_space}. Nevertheless, the choice of colour space in which colour features will be encoded in the prediction model can influence its performance. For simplicity, in this chapter RGB colour space will be assumed. Hence, a feature vector $\varphi$ is composed of three features, each representing a different component of the chosen colour space as in equation \ref{eq:fi_RGB}.
\begin{equation}
    \label{eq:fi_RGB}
    \varphi = \begin{bmatrix}
        \varphi_R\\ 
        \varphi_G\\ 
        \varphi_B
    \end{bmatrix}
\end{equation}
To obtain unary component of the energy function weight vector $w$ needs to be multiplied by the feature vector $\varphi$. For a given problem of classification, there is a separate weight vector associated with each class, being represented by one label from a set of available labels $L$ as in equation \ref{eq:e1_weight_vector}. 
\begin{equation}
    \label{eq:e1_weight_vector}
    E_1(y_i,x_i)= 
    \begin{Bmatrix}
        \left \langle w_{1,0}, \varphi({x_i}) \right \rangle & y_i = 0\\ 
        \left \langle w_{1,1}, \varphi({x_i}) \right \rangle & y_i = 1\\
         ...& ...\\ 
        \left \langle w_{1,L}, \varphi({x_i}) \right \rangle & y_i = L\\  
    \end{Bmatrix}
\end{equation}
Distinction between weight vector of different classes is required as each object class can be best characterised by different features. For example, given an object with label \textit{grass} a green component of the feature vector should be prioritised, while for label \textit{sky} it should be a blue component. As the task of image segmentation, meaning finding an optimal prediction $y^*$ for each pixel in an image, is equivalent to the problem of energy minimisation, weights which are associated with prioritised features should have relatively small values. Hence, with the same example of two labels \textit{grass} and \textit{sky} proper configuration of weights would be as in equation \ref{eq:weights_labels}.
\begin{equation}
    \label{eq:weights_labels}
    \begin{matrix} 
        w_{grass} = \begin{bmatrix}
            1.0\\ 
            0.0\\ 
            1.0
            \end{bmatrix}  
        & & &
        w_{sky} = \begin{bmatrix}
            1.0\\ 
            1.0\\ 
            0.0
            \end{bmatrix} 
    \end{matrix}
\end{equation}
Then, for example for fully blue pixels, with $\varphi = [0.0, 0.0, 1.0]$, the unary component of energy will be equal to 0.0 for label \textit{sky} and 1.0 for label \textit{grass}. Thus, label \textit{sky} will be chosen for such pixels, as the energy for this label is smaller than for other labels. 

When it comes to the second component of the energy function, a pairwise potential, it is responsible for smoothness of the predicted labels. It is aimed to handle a situation in which there is some noise in an image as it penalises a situation in which two neighbouring pixels have a different label assigned. Thus, a sample pixel that is surrounded by pixels with label $L_1$ will be more likely to have the same label even if the unary term is more prone to assign a different label to this pixel, because of its noised features. In the simplest form this second component of energy function can be expressed in terms of two weights which directly reflect pairwise energy value. If two pixels that form neighbouring nodes in a factor graph have the same label assigned, then an energy of the factor between them will be equal to weight $w_1$, if the have a different label assigned, then it will be $w_2$ as in equation \ref{eq:energy_pairwise}. Again, as the state of smaller energy is the one that is going to be chosen for a given factor, if the situation of two neighbouring pixels having the same label is to be promoted, then $w_1$ should have smaller value than $w_2$.
\begin{equation}
 \label{eq:energy_pairwise}
    E_2(y_i,y_j)=\begin{Bmatrix}
     w_1 & y_i=y_j \\ 
     w_2 & y_i \neq y_j
    \end{Bmatrix}
\end{equation}
Pairwise term of energy function provides higher-order information about relations neighbouring pixels, however, the notion of neighbours is different depending on the model used. In general, a neighbour is any pixel that is adjacent to the given pixel, however, neighbourhoods of larger size can also be used. In a situation in which larger neighbourhoods are used, factor graphs are highly beneficial as they can model more complicated relations between pixels in a clear and straightforward way.


 




, four label pairs
( , ) F F , ( , ) F B , ( , ) B F
 and
( , ) B B
 a